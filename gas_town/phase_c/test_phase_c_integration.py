#!/usr/bin/env python3
"""
Gas Town Phase C: Integration Test Suite
=======================================

Comprehensive test of the Phase C Intelligence Layer integration.
Tests all four core components working together:

1. Persistent Molecule State System
2. Enhanced Health Monitoring System
3. Swarm Coordinator System
4. ML-Driven Execution Planning System

This test validates the complete intelligence layer functionality.
"""

import asyncio
import time
import json
import tempfile
import shutil
from datetime import datetime, timezone, timedelta
from pathlib import Path
from typing import Dict, List, Any

# Import Phase C components
from persistent_molecule_state import PersistentMoleculeState, MoleculeState
from enhanced_health_monitor import EnhancedHealthMonitor, HealthLevel, HealthMetrics
from swarm_coordinator import SwarmCoordinator, TeamType, AgentCapability, WorkloadType
from ml_execution_planner import MLExecutionPlanner, PlanningStrategy, WorkflowPattern


class PhaseC_IntegrationTester:
    """
    Comprehensive integration tester for Gas Town Phase C Intelligence Layer.

    Tests all components individually and as an integrated system.
    """

    def __init__(self, test_dir: str = None):
        """Initialize the integration tester with temporary databases."""
        self.test_dir = Path(test_dir) if test_dir else Path(tempfile.mkdtemp(prefix="phase_c_test_"))
        self.test_results = {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "test_summary": {
                "total_tests": 0,
                "passed": 0,
                "failed": 0,
                "errors": []
            },
            "component_tests": {},
            "integration_tests": {}
        }

        # Initialize components with test databases
        self.molecule_state = PersistentMoleculeState(
            db_path=str(self.test_dir / "test_molecule_state.db")
        )

        self.health_monitor = EnhancedHealthMonitor(
            db_path=str(self.test_dir / "test_health_monitor.db"),
            molecule_state=self.molecule_state
        )

        self.swarm_coordinator = SwarmCoordinator(
            db_path=str(self.test_dir / "test_swarm_coordinator.db"),
            molecule_state=self.molecule_state,
            health_monitor=self.health_monitor
        )

        self.ml_planner = MLExecutionPlanner(
            db_path=str(self.test_dir / "test_ml_planner.db"),
            molecule_state=self.molecule_state,
            health_monitor=self.health_monitor,
            swarm_coordinator=self.swarm_coordinator
        )

        print(f"üß™ Phase C Integration Test initialized in {self.test_dir}")

    def run_all_tests(self) -> Dict[str, Any]:
        """Run all integration tests and return comprehensive results."""
        print("\n" + "=" * 70)
        print("üéØ RUNNING PHASE C INTELLIGENCE LAYER INTEGRATION TESTS")
        print("=" * 70)

        try:
            # Component-level tests
            print("\nüìã COMPONENT TESTS:")
            self._test_molecule_state_system()
            self._test_health_monitoring_system()
            self._test_swarm_coordination_system()
            self._test_ml_planning_system()

            # Integration tests
            print("\nüîó INTEGRATION TESTS:")
            self._test_crash_recovery_integration()
            self._test_health_aware_coordination()
            self._test_ml_optimized_execution()
            self._test_full_stack_workflow()

            # Performance tests
            print("\n‚ö° PERFORMANCE TESTS:")
            self._test_scalability()
            self._test_concurrent_operations()

        except Exception as e:
            self._record_error(f"Test suite failure: {e}")

        return self._generate_test_report()

    def _test_molecule_state_system(self) -> None:
        """Test the persistent molecule state system."""
        print("  üß¨ Testing Persistent Molecule State System...")
        test_name = "molecule_state_system"

        try:
            # Test molecule creation
            molecule = self.molecule_state.create_molecule(
                molecule_id="test_molecule_001",
                agent_name="TestAgent",
                initial_data={"step": "initialization", "progress": 0.0},
                gas_town_context={"convoy_id": "test_convoy"}
            )
            assert molecule.molecule_id == "test_molecule_001"
            print("    ‚úÖ Molecule creation")

            # Test checkpointing
            checkpoint_success = self.molecule_state.checkpoint_molecule(
                molecule_id="test_molecule_001",
                checkpoint_data={"step": "processing", "progress": 0.5},
                state=MoleculeState.RUNNING,
                rollback_point=True
            )
            assert checkpoint_success
            print("    ‚úÖ Molecule checkpointing")

            # Test history retrieval
            history = self.molecule_state.get_molecule_history("test_molecule_001")
            assert len(history) >= 2  # Initial + checkpoint
            print("    ‚úÖ History retrieval")

            # Test rollback capability
            rollback_point = self.molecule_state.find_rollback_point("test_molecule_001")
            assert rollback_point is not None
            print("    ‚úÖ Rollback point detection")

            # Test completion
            final_molecule = self.molecule_state.complete_molecule(
                molecule_id="test_molecule_001",
                final_data={"step": "completed", "progress": 1.0}
            )
            assert final_molecule.state == MoleculeState.COMPLETED
            print("    ‚úÖ Molecule completion")

            self._record_test_success(test_name, "All molecule state operations successful")

        except Exception as e:
            self._record_test_failure(test_name, f"Molecule state test failed: {e}")

    def _test_health_monitoring_system(self) -> None:
        """Test the enhanced health monitoring system."""
        print("  üè• Testing Enhanced Health Monitoring System...")
        test_name = "health_monitoring_system"

        try:
            # Start monitoring (but don't let it run too long)
            self.health_monitor.start_monitoring()
            print("    ‚úÖ Health monitoring startup")

            # Wait for initial data collection
            time.sleep(2)

            # Test health status retrieval
            health_summary = self.health_monitor.get_health_summary()
            assert "timestamp" in health_summary
            assert "monitoring_active" in health_summary
            print("    ‚úÖ Health summary generation")

            # Test dashboard generation
            dashboard = self.health_monitor.generate_health_dashboard()
            assert "GAS TOWN HEALTH DASHBOARD" in dashboard
            assert "SYSTEM RESOURCES" in dashboard
            print("    ‚úÖ Health dashboard generation")

            # Stop monitoring
            self.health_monitor.stop_monitoring()
            print("    ‚úÖ Health monitoring shutdown")

            self._record_test_success(test_name, "All health monitoring operations successful")

        except Exception as e:
            self._record_test_failure(test_name, f"Health monitoring test failed: {e}")

    def _test_swarm_coordination_system(self) -> None:
        """Test the swarm coordination system."""
        print("  üêù Testing Swarm Coordination System...")
        test_name = "swarm_coordination_system"

        try:
            # Register test agents
            agent1 = self.swarm_coordinator.register_agent(
                agent_name="TestAgent_Alpha",
                capabilities=[AgentCapability.FRONTEND_DEV, AgentCapability.TESTING],
                team_preferences=[TeamType.PARALLEL]
            )
            agent2 = self.swarm_coordinator.register_agent(
                agent_name="TestAgent_Beta",
                capabilities=[AgentCapability.BACKEND_DEV, AgentCapability.DATABASE_OPS],
                team_preferences=[TeamType.SPECIALIST]
            )
            agent3 = self.swarm_coordinator.register_agent(
                agent_name="TestAgent_Gamma",
                capabilities=[AgentCapability.COORDINATION, AgentCapability.ANALYSIS],
                team_preferences=[TeamType.MESH]
            )
            print("    ‚úÖ Agent registration")

            # Test team formation
            team = self.swarm_coordinator.form_team(
                workload=["task1", "task2", "task3"],
                required_capabilities=[AgentCapability.FRONTEND_DEV, AgentCapability.BACKEND_DEV],
                team_type=TeamType.PARALLEL
            )
            assert team is not None
            assert len(team.member_agents) >= 2
            print("    ‚úÖ Team formation")

            # Test work distribution
            work_plan = self.swarm_coordinator.distribute_work(
                work_items=["item1", "item2", "item3", "item4"]
            )
            assert work_plan.load_balance_score >= 0.0
            print("    ‚úÖ Work distribution")

            # Test swarm status
            swarm_status = self.swarm_coordinator.get_swarm_status()
            assert swarm_status["swarm_metrics"]["total_agents"] == 3
            print("    ‚úÖ Swarm status reporting")

            # Test coordination dashboard
            dashboard = self.swarm_coordinator.generate_coordination_dashboard()
            assert "SWARM COORDINATION DASHBOARD" in dashboard
            print("    ‚úÖ Coordination dashboard")

            self._record_test_success(test_name, "All swarm coordination operations successful")

        except Exception as e:
            self._record_test_failure(test_name, f"Swarm coordination test failed: {e}")

    def _test_ml_planning_system(self) -> None:
        """Test the ML-driven execution planning system."""
        print("  ü§ñ Testing ML-Driven Execution Planning System...")
        test_name = "ml_planning_system"

        try:
            # Create test workflow
            workflow_tasks = [
                {
                    'id': 'ml_test_task1',
                    'name': 'Setup authentication service',
                    'complexity': 0.7,
                    'resource_intensity': 0.6,
                    'dependencies': [],
                    'required_capabilities': ['backend_dev', 'security']
                },
                {
                    'id': 'ml_test_task2',
                    'name': 'Build user dashboard',
                    'complexity': 0.5,
                    'resource_intensity': 0.4,
                    'dependencies': ['ml_test_task1'],
                    'required_capabilities': ['frontend_dev']
                },
                {
                    'id': 'ml_test_task3',
                    'name': 'Integration testing',
                    'complexity': 0.6,
                    'resource_intensity': 0.3,
                    'dependencies': ['ml_test_task1', 'ml_test_task2'],
                    'required_capabilities': ['testing']
                }
            ]

            # Test execution plan generation
            plan = self.ml_planner.generate_execution_plan(
                workflow_tasks=workflow_tasks,
                strategy=PlanningStrategy.PERFORMANCE_OPTIMAL,
                constraints={
                    'deadline': (datetime.now(timezone.utc) + timedelta(hours=8)).isoformat(),
                    'urgency': 0.6
                }
            )

            assert plan.plan_id is not None
            assert plan.workflow_pattern in WorkflowPattern
            assert plan.confidence_score >= 0.0 and plan.confidence_score <= 1.0
            assert len(plan.task_sequence) == 3
            print("    ‚úÖ Execution plan generation")

            # Test planning insights
            insights = self.ml_planner.get_planning_insights()
            assert "timestamp" in insights
            print("    ‚úÖ Planning insights generation")

            # Test workflow outcome recording
            test_results = {
                'duration_hours': 6.2,
                'success_rate': 0.95,
                'resource_utilization': {'cpu': 0.58, 'memory': 0.42},
                'failure_points': [],
                'performance_metrics': {'throughput': 1.8, 'quality_score': 0.91}
            }

            self.ml_planner.record_workflow_outcome(
                workflow_id='ml_integration_test_001',
                planned_plan=plan,
                actual_results=test_results
            )
            print("    ‚úÖ Workflow outcome recording")

            # Test real-time optimization
            current_state = {
                'predicted_duration': 8.0,
                'elapsed_time': 3.2,
                'completion_ratio': 0.35
            }
            optimization = self.ml_planner.optimize_current_execution(current_state)
            assert "recommendations" in optimization
            print("    ‚úÖ Real-time optimization")

            self._record_test_success(test_name, "All ML planning operations successful")

        except Exception as e:
            self._record_test_failure(test_name, f"ML planning test failed: {e}")

    def _test_crash_recovery_integration(self) -> None:
        """Test crash recovery integration between components."""
        print("  üí• Testing Crash Recovery Integration...")
        test_name = "crash_recovery_integration"

        try:
            # Create molecule for crash test
            crash_molecule = self.molecule_state.create_molecule(
                molecule_id="crash_test_molecule",
                agent_name="CrashTestAgent",
                initial_data={"critical_work": True, "checkpoint_id": 1}
            )

            # Add checkpoint
            self.molecule_state.checkpoint_molecule(
                molecule_id="crash_test_molecule",
                checkpoint_data={"critical_work": True, "checkpoint_id": 2, "progress": 0.7},
                rollback_point=True
            )

            # Simulate agent crash by marking as failed
            self.molecule_state.fail_molecule(
                molecule_id="crash_test_molecule",
                error_info={"error_type": "agent_crash", "timestamp": datetime.now().isoformat()}
            )
            print("    ‚úÖ Crash simulation")

            # Test crash detection
            crashed_agents = self.molecule_state.detect_crashed_agents()
            # Note: This might be empty in test as we don't have real heartbeat timeouts
            print("    ‚úÖ Crash detection")

            # Test recovery
            recovery_snapshot = self.molecule_state.rollback_molecule("crash_test_molecule")
            if recovery_snapshot:
                assert recovery_snapshot.state == MoleculeState.ROLLED_BACK
                print("    ‚úÖ Crash recovery rollback")
            else:
                print("    ‚ö†Ô∏è  No rollback point (expected in test)")

            self._record_test_success(test_name, "Crash recovery integration functional")

        except Exception as e:
            self._record_test_failure(test_name, f"Crash recovery integration failed: {e}")

    def _test_health_aware_coordination(self) -> None:
        """Test health monitoring integration with swarm coordination."""
        print("  üîó Testing Health-Aware Coordination...")
        test_name = "health_aware_coordination"

        try:
            # Start monitoring briefly
            self.health_monitor.start_monitoring()
            time.sleep(1)

            # Get current health metrics
            health_summary = self.health_monitor.get_health_summary()
            print("    ‚úÖ Health metrics collection")

            # Test swarm status with health awareness
            swarm_status = self.swarm_coordinator.get_swarm_status()

            # Verify coordination considers health
            assert "swarm_metrics" in swarm_status
            print("    ‚úÖ Health-aware swarm status")

            # Stop monitoring
            self.health_monitor.stop_monitoring()

            self._record_test_success(test_name, "Health-aware coordination functional")

        except Exception as e:
            self._record_test_failure(test_name, f"Health-aware coordination failed: {e}")

    def _test_ml_optimized_execution(self) -> None:
        """Test ML planner integration with swarm coordination."""
        print("  üéØ Testing ML-Optimized Execution...")
        test_name = "ml_optimized_execution"

        try:
            # Create complex workflow
            complex_workflow = [
                {
                    'id': 'complex_task_1',
                    'name': 'Database migration',
                    'complexity': 0.9,
                    'resource_intensity': 0.8,
                    'dependencies': [],
                    'required_capabilities': ['database_ops', 'backend_dev']
                },
                {
                    'id': 'complex_task_2',
                    'name': 'API endpoint creation',
                    'complexity': 0.6,
                    'resource_intensity': 0.5,
                    'dependencies': ['complex_task_1'],
                    'required_capabilities': ['backend_dev']
                },
                {
                    'id': 'complex_task_3',
                    'name': 'Frontend component updates',
                    'complexity': 0.7,
                    'resource_intensity': 0.4,
                    'dependencies': ['complex_task_2'],
                    'required_capabilities': ['frontend_dev']
                },
                {
                    'id': 'complex_task_4',
                    'name': 'End-to-end testing',
                    'complexity': 0.8,
                    'resource_intensity': 0.6,
                    'dependencies': ['complex_task_3'],
                    'required_capabilities': ['testing', 'analysis']
                }
            ]

            # Generate ML-optimized plan
            optimized_plan = self.ml_planner.generate_execution_plan(
                workflow_tasks=complex_workflow,
                strategy=PlanningStrategy.ADAPTIVE,
                constraints={'urgency': 0.8}
            )

            assert optimized_plan.workflow_pattern != None
            assert len(optimized_plan.task_sequence) == 4
            print("    ‚úÖ Complex workflow optimization")

            # Test team assignment optimization
            assert len(optimized_plan.team_assignments) > 0
            print("    ‚úÖ ML-driven team assignments")

            # Test risk assessment
            assert len(optimized_plan.risk_factors) >= 0
            print("    ‚úÖ Risk factor assessment")

            # Test contingency planning
            assert len(optimized_plan.contingency_plans) >= 0
            print("    ‚úÖ Contingency plan generation")

            self._record_test_success(test_name, "ML-optimized execution functional")

        except Exception as e:
            self._record_test_failure(test_name, f"ML-optimized execution failed: {e}")

    def _test_full_stack_workflow(self) -> None:
        """Test complete end-to-end workflow through all Phase C components."""
        print("  üîÑ Testing Full-Stack Workflow...")
        test_name = "full_stack_workflow"

        try:
            # 1. Start all systems
            self.health_monitor.start_monitoring()
            self.swarm_coordinator.start_coordination()
            self.ml_planner.start_ml_planning()
            time.sleep(1)
            print("    ‚úÖ All systems started")

            # 2. Register agents for full workflow
            for i, agent_name in enumerate(["FullStack_Alpha", "FullStack_Beta", "FullStack_Gamma"]):
                self.swarm_coordinator.register_agent(
                    agent_name=agent_name,
                    capabilities=[
                        AgentCapability.FRONTEND_DEV if i % 3 == 0 else
                        AgentCapability.BACKEND_DEV if i % 3 == 1 else
                        AgentCapability.TESTING
                    ]
                )
            print("    ‚úÖ Agents registered")

            # 3. Create comprehensive workflow
            full_workflow = [
                {
                    'id': 'fw_setup',
                    'name': 'Project setup and initialization',
                    'complexity': 0.4,
                    'resource_intensity': 0.3,
                    'dependencies': [],
                    'required_capabilities': ['coordination']
                },
                {
                    'id': 'fw_backend',
                    'name': 'Backend service implementation',
                    'complexity': 0.8,
                    'resource_intensity': 0.7,
                    'dependencies': ['fw_setup'],
                    'required_capabilities': ['backend_dev']
                },
                {
                    'id': 'fw_frontend',
                    'name': 'Frontend interface development',
                    'complexity': 0.7,
                    'resource_intensity': 0.5,
                    'dependencies': ['fw_backend'],
                    'required_capabilities': ['frontend_dev']
                },
                {
                    'id': 'fw_testing',
                    'name': 'Comprehensive testing suite',
                    'complexity': 0.6,
                    'resource_intensity': 0.4,
                    'dependencies': ['fw_frontend'],
                    'required_capabilities': ['testing']
                }
            ]

            # 4. Generate ML-optimized execution plan
            execution_plan = self.ml_planner.generate_execution_plan(
                workflow_tasks=full_workflow,
                strategy=PlanningStrategy.LOAD_BALANCED,
                constraints={
                    'deadline': (datetime.now(timezone.utc) + timedelta(hours=12)).isoformat(),
                    'urgency': 0.7,
                    'quality_threshold': 0.85
                }
            )
            print("    ‚úÖ Execution plan generated")

            # 5. Create persistent molecules for each task
            molecules = []
            for task in full_workflow:
                molecule = self.molecule_state.create_molecule(
                    molecule_id=f"fullstack_{task['id']}",
                    agent_name="FullStack_Alpha",  # Will be reassigned by coordinator
                    initial_data={"task_data": task, "workflow_plan": execution_plan.plan_id},
                    gas_town_context={"execution_plan_id": execution_plan.plan_id}
                )
                molecules.append(molecule)
            print("    ‚úÖ Persistent molecules created")

            # 6. Form teams based on ML recommendations
            teams = []
            for team_id, task_list in execution_plan.team_assignments.items():
                if task_list:  # Only form teams that have work
                    team = self.swarm_coordinator.form_team(
                        workload=task_list,
                        required_capabilities=[AgentCapability.COORDINATION],  # Simplified for test
                        team_type=TeamType.PARALLEL
                    )
                    if team:
                        teams.append(team)
            print(f"    ‚úÖ {len(teams)} teams formed")

            # 7. Simulate workflow execution with checkpoints
            for i, molecule in enumerate(molecules):
                # Simulate progress checkpointing
                self.molecule_state.checkpoint_molecule(
                    molecule_id=molecule.molecule_id,
                    checkpoint_data={"progress": 0.5, "phase": "in_progress"},
                    state=MoleculeState.RUNNING,
                    rollback_point=True
                )

                # Complete molecule
                self.molecule_state.complete_molecule(
                    molecule_id=molecule.molecule_id,
                    final_data={"progress": 1.0, "phase": "completed"}
                )
                print(f"      ‚úÖ Molecule {i+1}/{len(molecules)} completed")

            # 8. Record workflow outcome for ML learning
            workflow_outcome = {
                'duration_hours': 10.5,
                'success_rate': 0.92,
                'resource_utilization': {'cpu': 0.65, 'memory': 0.55},
                'failure_points': [],
                'performance_metrics': {
                    'throughput': 2.3,
                    'quality_score': 0.89,
                    'team_efficiency': 0.87
                },
                'context_features': {
                    'complexity': 0.65,
                    'coordination_overhead': 0.25,
                    'agent_experience': 0.75
                }
            }

            self.ml_planner.record_workflow_outcome(
                workflow_id='full_stack_integration_test',
                planned_plan=execution_plan,
                actual_results=workflow_outcome
            )
            print("    ‚úÖ Workflow outcome recorded for ML learning")

            # 9. Get final system status
            final_health = self.health_monitor.get_health_summary()
            final_swarm = self.swarm_coordinator.get_swarm_status()
            final_insights = self.ml_planner.get_planning_insights()

            assert final_health["monitoring_active"] == True
            assert final_swarm["coordination_active"] == True
            print("    ‚úÖ All systems operational")

            # 10. Stop all systems gracefully
            self.ml_planner.stop_ml_planning()
            self.swarm_coordinator.stop_coordination()
            self.health_monitor.stop_monitoring()
            print("    ‚úÖ All systems stopped gracefully")

            self._record_test_success(test_name,
                f"Full-stack workflow completed: {len(molecules)} molecules, "
                f"{len(teams)} teams, ML optimization successful")

        except Exception as e:
            self._record_test_failure(test_name, f"Full-stack workflow failed: {e}")

    def _test_scalability(self) -> None:
        """Test system scalability with multiple agents and concurrent operations."""
        print("  üìà Testing Scalability...")
        test_name = "scalability_test"

        try:
            # Register many agents
            agent_count = 15  # Test with significant agent count
            for i in range(agent_count):
                capabilities = [
                    AgentCapability.FRONTEND_DEV,
                    AgentCapability.BACKEND_DEV,
                    AgentCapability.TESTING,
                    AgentCapability.DATABASE_OPS
                ][i % 4]

                self.swarm_coordinator.register_agent(
                    agent_name=f"ScaleTest_Agent_{i:02d}",
                    capabilities=[capabilities],
                    team_preferences=[TeamType.PARALLEL, TeamType.PIPELINE]
                )

            print(f"    ‚úÖ {agent_count} agents registered")

            # Create large workload
            large_workload = [f"scale_task_{i:03d}" for i in range(50)]

            # Test work distribution
            start_time = time.time()
            distribution_plan = self.swarm_coordinator.distribute_work(large_workload)
            distribution_time = time.time() - start_time

            assert distribution_plan.load_balance_score >= 0.0
            assert distribution_time < 5.0  # Should complete within 5 seconds
            print(f"    ‚úÖ Large workload distributed in {distribution_time:.2f}s")

            # Test multiple team formations
            start_time = time.time()
            teams_formed = 0
            for i in range(5):  # Form 5 teams
                team = self.swarm_coordinator.form_team(
                    workload=[f"team_{i}_task_{j}" for j in range(3)],
                    required_capabilities=[AgentCapability.FRONTEND_DEV, AgentCapability.BACKEND_DEV],
                    team_type=TeamType.PARALLEL
                )
                if team:
                    teams_formed += 1

            team_formation_time = time.time() - start_time
            assert teams_formed >= 3  # Should form at least 3 teams
            assert team_formation_time < 3.0  # Should complete within 3 seconds
            print(f"    ‚úÖ {teams_formed} teams formed in {team_formation_time:.2f}s")

            self._record_test_success(test_name,
                f"Scalability validated: {agent_count} agents, 50 tasks, {teams_formed} teams")

        except Exception as e:
            self._record_test_failure(test_name, f"Scalability test failed: {e}")

    def _test_concurrent_operations(self) -> None:
        """Test concurrent operations across all systems."""
        print("  ‚ö° Testing Concurrent Operations...")
        test_name = "concurrent_operations"

        try:
            import threading

            results = {"errors": [], "successes": 0}

            def concurrent_molecule_operations():
                try:
                    for i in range(5):
                        mol_id = f"concurrent_mol_{threading.current_thread().ident}_{i}"
                        mol = self.molecule_state.create_molecule(
                            molecule_id=mol_id,
                            agent_name=f"ConcurrentAgent_{i}",
                            initial_data={"thread_test": True}
                        )
                        self.molecule_state.checkpoint_molecule(
                            molecule_id=mol_id,
                            checkpoint_data={"checkpoint": i},
                            state=MoleculeState.RUNNING
                        )
                        self.molecule_state.complete_molecule(mol_id)
                    results["successes"] += 1
                except Exception as e:
                    results["errors"].append(f"Molecule thread error: {e}")

            def concurrent_team_operations():
                try:
                    for i in range(3):
                        team = self.swarm_coordinator.form_team(
                            workload=[f"concurrent_work_{i}"],
                            required_capabilities=[AgentCapability.COORDINATION],
                            team_type=TeamType.PARALLEL
                        )
                        if team:
                            results["successes"] += 1
                except Exception as e:
                    results["errors"].append(f"Team thread error: {e}")

            # Start concurrent operations
            threads = []
            for _ in range(3):  # 3 molecule threads
                t = threading.Thread(target=concurrent_molecule_operations)
                threads.append(t)
                t.start()

            for _ in range(2):  # 2 team threads
                t = threading.Thread(target=concurrent_team_operations)
                threads.append(t)
                t.start()

            # Wait for completion
            for t in threads:
                t.join(timeout=10.0)

            assert len(results["errors"]) == 0, f"Concurrent errors: {results['errors']}"
            assert results["successes"] >= 3  # Should have some successful operations
            print(f"    ‚úÖ {results['successes']} concurrent operations successful")

            self._record_test_success(test_name,
                f"Concurrent operations successful: {results['successes']} ops, 0 errors")

        except Exception as e:
            self._record_test_failure(test_name, f"Concurrent operations test failed: {e}")

    def _record_test_success(self, test_name: str, message: str) -> None:
        """Record a successful test."""
        self.test_results["test_summary"]["total_tests"] += 1
        self.test_results["test_summary"]["passed"] += 1
        self.test_results["component_tests"][test_name] = {
            "status": "PASSED",
            "message": message,
            "timestamp": datetime.now(timezone.utc).isoformat()
        }

    def _record_test_failure(self, test_name: str, error_message: str) -> None:
        """Record a failed test."""
        self.test_results["test_summary"]["total_tests"] += 1
        self.test_results["test_summary"]["failed"] += 1
        self.test_results["test_summary"]["errors"].append(error_message)
        self.test_results["component_tests"][test_name] = {
            "status": "FAILED",
            "message": error_message,
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
        print(f"    ‚ùå {test_name}: {error_message}")

    def _record_error(self, error_message: str) -> None:
        """Record a general error."""
        self.test_results["test_summary"]["errors"].append(error_message)
        print(f"‚ùå ERROR: {error_message}")

    def _generate_test_report(self) -> Dict[str, Any]:
        """Generate comprehensive test report."""
        summary = self.test_results["test_summary"]

        print("\n" + "=" * 70)
        print("üìä PHASE C INTEGRATION TEST RESULTS")
        print("=" * 70)

        print(f"Total Tests: {summary['total_tests']}")
        print(f"‚úÖ Passed: {summary['passed']}")
        print(f"‚ùå Failed: {summary['failed']}")

        if summary['failed'] == 0:
            print("üéâ ALL TESTS PASSED - PHASE C INTELLIGENCE LAYER VALIDATED!")
        else:
            print(f"‚ö†Ô∏è  {summary['failed']} tests failed - review errors")

        success_rate = (summary['passed'] / max(summary['total_tests'], 1)) * 100
        print(f"Success Rate: {success_rate:.1f}%")

        # Component test results
        print("\nüìã COMPONENT TEST RESULTS:")
        for test_name, result in self.test_results["component_tests"].items():
            status_emoji = "‚úÖ" if result["status"] == "PASSED" else "‚ùå"
            print(f"  {status_emoji} {test_name}: {result['status']}")

        # Add overall assessment
        self.test_results["overall_assessment"] = {
            "phase_c_status": "VALIDATED" if summary['failed'] == 0 else "ISSUES_FOUND",
            "success_rate": success_rate,
            "intelligence_layer_functional": summary['failed'] == 0,
            "ready_for_production": summary['failed'] == 0 and success_rate >= 90.0
        }

        return self.test_results

    def cleanup(self) -> None:
        """Clean up test environment."""
        try:
            # Stop all running systems
            if hasattr(self, 'health_monitor'):
                self.health_monitor.stop_monitoring()
            if hasattr(self, 'swarm_coordinator'):
                self.swarm_coordinator.stop_coordination()
            if hasattr(self, 'ml_planner'):
                self.ml_planner.stop_ml_planning()

            # Clean up test directory
            if self.test_dir.exists():
                shutil.rmtree(self.test_dir)

            print(f"üßπ Test cleanup completed - {self.test_dir} removed")

        except Exception as e:
            print(f"‚ö†Ô∏è  Cleanup warning: {e}")


# Main test execution
if __name__ == "__main__":
    print("üöÄ Starting Phase C Intelligence Layer Integration Test")

    tester = PhaseC_IntegrationTester()

    try:
        test_results = tester.run_all_tests()

        # Save results
        results_file = Path("phase_c_test_results.json")
        with open(results_file, 'w') as f:
            json.dump(test_results, f, indent=2)
        print(f"\nüìÑ Test results saved to {results_file}")

        # Print final status
        if test_results["overall_assessment"]["intelligence_layer_functional"]:
            print("\nüéØ PHASE C INTELLIGENCE LAYER: FULLY OPERATIONAL")
            print("   Ready for production deployment!")
        else:
            print("\n‚ö†Ô∏è  PHASE C INTELLIGENCE LAYER: ISSUES DETECTED")
            print("   Review test results before deployment")

    finally:
        tester.cleanup()